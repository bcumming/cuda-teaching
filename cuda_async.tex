%++++++++++++++++++++++++++++++++
\cscschapter{Concurrency}
%++++++++++++++++++++++++++++++++

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Concurrency}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \emph{Concurrency} is the ability to perform multiple CUDA operations simultaneously
    \begin{itemize}
        \item CUDA kernels
        \item copying from host to device
        \item copying from device to host
        \item operations on the host CPU
    \end{itemize}

    We can take advantage of concurrency to:
    \begin{itemize}
        \item both CPU and GPU can work at the same time
        \item multiple tasks can be run on GPU simultaneously
        \item we can overlap communication and computation
    \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{CPU and GPU operations are asynchronous}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{codecolumn}{host code}
                \begin{lstlisting}[style=boxcudatiny]
kernel_1<<<...>>>(...);
kernel_2<<<...>>>(...);
host_1(...);
host_2(...);
                \end{lstlisting}
            \end{codecolumn}
        The host:
        \begin{itemize}
            \item launches the two CUDA kernels
            \item then executes host calls sequentially 
        \end{itemize}
        The GPU:
        \begin{itemize}
            \item executes asynchronously to host
            \item executes kernels sequentially
        \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \includegraphics[width=\textwidth]{./images/async_null.pdf}
        \end{column}
    \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{CUDA Support for Asynchronous Execution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    The CUDA language and runtime libraries provide mechanisms for coordinating asynchronous GPU execution

    \begin{itemize}
        \item \emph{CUDA streams} can concurrently run independent kernels and memory transfers
        \item \emph{CUDA events} can be used to synchronize streams and query the status of kernels and transfers
    \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Streams}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    A CUDA stream is is a sequence of operations that execute in \emph{issue order} on the GPU
    \begin{itemize}
        \item CUDA operations are kernels and copies between host and device memory spaces
    \end{itemize}

    \begin{info}{streams and concurrency}
        \begin{itemize}
            \item operations in different streams \emph{may} run concurrently
            \item operations in the same stream \emph{are} executed sequentially
            \item if no stream is specified, all kernels are launched in the default stream
        \end{itemize}
    \end{info}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Streams}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    A stream is represented using a \lst{cudaStream_t} type
    \begin{itemize}
        \item \lst{cudaStreamCreate(cudaStream_t* s)} and \lst{cudaStreamDestroy(cudaStream_t s)} can be used to create and free CUDA streams respectively
        \item To launch a kernel on a stream specify the stream id as a fourth parameter to the launch syntax \\
            \begin{center} \lst{kernel<<<grid_dim, block_dim, shared_size, stream>>>(...)} \end{center}
        \item the default CUDA stream is the \lst{NULL} stream, or stream 0 (\lst{cudaStream_t} is an integer)
    \end{itemize}

    \begin{code}{basic cuda stream useage}
        \begin{lstlisting}[style=boxcudatiny]
// create stream
cudaStream_t stream;
cudaStreamCreate(&stream);
// launch kernel in stream
my_kernel<<<grid_dim, block_dim, shared_size, stream>>>(..)
// release stream when finished
cudaStreamDestroy(stream);
        \end{lstlisting}
\end{code}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Asynchronous device execution example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{columns}[T]
        \begin{column}{0.45\textwidth}
            \begin{codecolumn}{host code}
                \begin{lstlisting}[style=boxcudatiny]
kernel_1<<<,,,stream_1>>>();
kernel_2<<<,,,stream_2>>>();
kernel_3<<<,,,stream_1>>>();
                \end{lstlisting}
            \end{codecolumn}
            \begin{itemize}
                \item \footnotesize \lst{kernel_1} and \lst{kernel_2} are serialized in \lst{stream_1}
                \item \lst{kernel_2} can run asynchronously in \lst{stream_2}
                \item note that \lst{kernel_2} will only run concurrently if there are sufficient resources available on the GPU, i.e. if \lst{kernel_1} is not using all of the SMXs.
            \end{itemize}
        \end{column}
        \begin{column}{0.6\textwidth}
            \includegraphics[width=\textwidth]{./images/async_two_streams.pdf}
        \end{column}
    \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Asynchronous copy}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    \begin{info}{asynchronous copy}
        \centering \lst{cudaMemcpyAsync(*dst, *src, count, kind, cudaStream_t stream = 0);}
        \begin{itemize}
            \item takes an additional parameter stream, which is 0 by default
            \item returns immediately after initiating copy
            \begin{itemize}
                \item host can do work while copy is performed
            \end{itemize}
            \item only if \emph{pinned memory} is used
        \end{itemize}
    \end{info}

    \begin{info}{pinned memory}
        \centering \lst{cudaMallocHost(**ptr, size);}
        \begin{itemize}
            \item allocates $size$ bytes of pinned host memory
        \end{itemize}
    \end{info}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Asynchronous copy example: streaming}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    Streaming workloads have computations that can be performed independently, e.g. our \axpy example:
    \begin{itemize}
        \item data in host memory has to be copied to the device, and the result copied back after the kernel is computed.
        \item we can overlap the copies with the kernel calls by breaking the data into chunks.
    \end{itemize}
    \includegraphics[width=\textwidth]{./images/overlap.pdf}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Events}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    To implement the streaming workload we have to coordinate operations on the GPU
    \begin{itemize}
        \item e.g. wait for chunk to finish copying H2D before launching kernel.
    \end{itemize}

    CUDA provides events for this purpose
    \begin{itemize}
        \item synchronize tasks in different streams:
        \begin{itemize}
            \item don't start kernel in kernel stream until data copy stream has finished.
            \item wait until required data has finished copy from host before launching kernel
        \end{itemize}
        \item allow us to query status of concurrent tasks
        \begin{itemize}
            \item has kernel finished/started yet?
            \item how long did a kernel take to compute?
        \end{itemize}
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Events}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    How to create and event

    How to destroy an event

    How to insert an event into a stream

    How to make a stream wait on an event
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Events : timing example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    timing kernel execution on GPU requires events

    code
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Events : copy-kernel synchronization example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    code
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercises}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
        \item time to visit \lst{util.h} and add helpers for asynchronous copy
        \item just give the event and stream wrappers ``as is''
        \begin{itemize}
            \item walk through their use in the memcpy example
        \end{itemize}
        \item fire up nvprof
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Asynchronous example: streaming}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    Streaming is a workload where we can break data and work into chunks
    \begin{itemize}
        \item work on one chunk of data while the next chunk is being sent
        \item send each chunk back to host and take next available chunk of work
        \item there has to be enough work in each chunk to hide ...
    \end{itemize}

    Take, for example our axpy example...
    \begin{itemize}
        \item clearly no amount of overlap will help us
        \item note that we get full speed both directions
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Asynchronous example: streaming}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    Show Newton kernel : lotsa work
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Streams: rule of thumb}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    Ideally for most workloads you don't want to rely on streams to fill the GPU with work
    \begin{itemize}
        \item a sign that the working set per GPU is not large enough
        \item full concurrency is difficult in practice
        \begin{itemize}
            \item a low-level optimization strategy for the last few \%
        \end{itemize}
        \item this isn't a hard and fast rule
    \end{itemize}

    Streams come into their own for overlapping communication and computation
    \begin{itemize}
        \item possible to transfer data in both directions concurrently with kernels execution
    \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercises}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    Overlapping work for Newton
\end{frame}
